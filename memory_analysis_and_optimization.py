#!/usr/bin/env python3
"""
Memory Analysis and Optimization - Fix memory allocation inefficiencies
Analyze and optimize VRAM/GTT/RAM usage patterns
"""

import psutil
import os
import gc
import logging
import numpy as np
from pathlib import Path
import time

logger = logging.getLogger(__name__)

class MemoryAnalyzer:
    """Analyze and optimize memory usage patterns"""
    
    def __init__(self):
        self.initial_memory = self.get_memory_usage()
        logger.info("ğŸ” Memory Analyzer initialized")
    
    def get_memory_usage(self):
        """Get comprehensive memory usage information"""
        memory_info = {}
        
        # System memory
        mem = psutil.virtual_memory()
        memory_info['system'] = {
            'total_gb': mem.total / (1024**3),
            'used_gb': mem.used / (1024**3),
            'available_gb': mem.available / (1024**3),
            'percent': mem.percent
        }
        
        # GPU memory (if available)
        try:
            with open('/sys/class/drm/card0/device/mem_info_vram_used', 'r') as f:
                vram_used = int(f.read().strip())
            with open('/sys/class/drm/card0/device/mem_info_vram_total', 'r') as f:
                vram_total = int(f.read().strip())
            
            memory_info['gpu'] = {
                'vram_used_gb': vram_used / (1024**3),
                'vram_total_gb': vram_total / (1024**3),
                'vram_percent': (vram_used / vram_total) * 100
            }
        except:
            memory_info['gpu'] = {'error': 'GPU memory info not available'}
        
        # GTT memory (GPU-accessible system memory)
        try:
            with open('/sys/class/drm/card0/device/mem_info_gtt_used', 'r') as f:
                gtt_used = int(f.read().strip())
            with open('/sys/class/drm/card0/device/mem_info_gtt_total', 'r') as f:
                gtt_total = int(f.read().strip())
            
            memory_info['gtt'] = {
                'gtt_used_gb': gtt_used / (1024**3),
                'gtt_total_gb': gtt_total / (1024**3),
                'gtt_percent': (gtt_used / gtt_total) * 100
            }
        except:
            memory_info['gtt'] = {'error': 'GTT memory info not available'}
        
        # Linux file cache
        try:
            with open('/proc/meminfo', 'r') as f:
                meminfo = f.read()
            
            cache_kb = 0
            buffers_kb = 0
            for line in meminfo.split('\n'):
                if line.startswith('Cached:'):
                    cache_kb = int(line.split()[1])
                elif line.startswith('Buffers:'):
                    buffers_kb = int(line.split()[1])
            
            memory_info['cache'] = {
                'cache_gb': cache_kb / (1024**2),
                'buffers_gb': buffers_kb / (1024**2),
                'total_cache_gb': (cache_kb + buffers_kb) / (1024**2)
            }
        except:
            memory_info['cache'] = {'error': 'Cache info not available'}
        
        return memory_info
    
    def print_memory_analysis(self, title="Memory Usage Analysis"):
        """Print detailed memory analysis"""
        mem = self.get_memory_usage()
        
        logger.info(f"\nğŸ“Š {title}")
        logger.info("=" * 60)
        
        # System memory
        if 'system' in mem:
            s = mem['system']
            logger.info(f"ğŸ–¥ï¸  System Memory:")
            logger.info(f"   Total: {s['total_gb']:.1f} GB")
            logger.info(f"   Used:  {s['used_gb']:.1f} GB ({s['percent']:.1f}%)")
            logger.info(f"   Free:  {s['available_gb']:.1f} GB")
        
        # GPU VRAM
        if 'gpu' in mem and 'error' not in mem['gpu']:
            g = mem['gpu']
            logger.info(f"ğŸ® GPU VRAM:")
            logger.info(f"   Total: {g['vram_total_gb']:.1f} GB")
            logger.info(f"   Used:  {g['vram_used_gb']:.1f} GB ({g['vram_percent']:.1f}%)")
            logger.info(f"   Free:  {g['vram_total_gb'] - g['vram_used_gb']:.1f} GB")
        
        # GTT Memory
        if 'gtt' in mem and 'error' not in mem['gtt']:
            gtt = mem['gtt']
            logger.info(f"ğŸ”„ GTT Memory (GPU-accessible system RAM):")
            logger.info(f"   Total: {gtt['gtt_total_gb']:.1f} GB")
            logger.info(f"   Used:  {gtt['gtt_used_gb']:.1f} GB ({gtt['gtt_percent']:.1f}%)")
            logger.info(f"   Free:  {gtt['gtt_total_gb'] - gtt['gtt_used_gb']:.1f} GB")
        
        # File cache
        if 'cache' in mem and 'error' not in mem['cache']:
            c = mem['cache']
            logger.info(f"ğŸ’¾ Linux File Cache:")
            logger.info(f"   Page Cache: {c['cache_gb']:.1f} GB")
            logger.info(f"   Buffers:    {c['buffers_gb']:.1f} GB")
            logger.info(f"   Total:      {c['total_cache_gb']:.1f} GB")
        
        logger.info("=" * 60)
        
        return mem
    
    def analyze_memory_allocation_issues(self):
        """Analyze why memory allocation is inefficient"""
        logger.info("\nğŸ” Analyzing Memory Allocation Issues...")
        
        current_mem = self.get_memory_usage()
        
        # Issue 1: Over-allocation analysis
        logger.info("\nâŒ Issue Analysis:")
        
        if 'gtt' in current_mem and 'error' not in current_mem['gtt']:
            gtt_used = current_mem['gtt']['gtt_used_gb']
            if gtt_used > 30:  # Model should be ~26GB
                logger.info(f"   ğŸš¨ GTT over-allocation: {gtt_used:.1f} GB (should be ~26GB)")
                logger.info("   ğŸ’¡ Cause: Likely duplicate allocations or fragmentation")
        
        if 'gpu' in current_mem and 'error' not in current_mem['gpu']:
            vram_used = current_mem['gpu']['vram_used_gb']
            if vram_used < 10:  # Should use more VRAM
                logger.info(f"   ğŸš¨ VRAM under-utilization: {vram_used:.1f} GB (should use ~15GB)")
                logger.info("   ğŸ’¡ Cause: Weights allocated to GTT instead of VRAM")
        
        if 'cache' in current_mem and 'error' not in current_mem['cache']:
            cache_gb = current_mem['cache']['total_cache_gb']
            if cache_gb > 20:
                logger.info(f"   ğŸš¨ Excessive file cache: {cache_gb:.1f} GB")
                logger.info("   ğŸ’¡ Cause: Memory-mapped files not being released")
        
        # Issue 2: Memory fragmentation
        logger.info("\nğŸ”§ Root Cause Analysis:")
        logger.info("   1. Memory-mapped files stay in cache after loading")
        logger.info("   2. GTT allocation may be duplicating VRAM data")
        logger.info("   3. Buffer allocation strategy may be inefficient")
        logger.info("   4. Garbage collection not releasing file handles")
    
    def optimize_memory_allocation(self):
        """Implement memory allocation optimizations"""
        logger.info("\nğŸš€ Implementing Memory Optimizations...")
        
        # Optimization 1: Clear file cache
        self._clear_file_cache()
        
        # Optimization 2: Force garbage collection
        self._force_garbage_collection()
        
        # Optimization 3: Optimize buffer allocation strategy
        self._optimize_buffer_allocation()
        
        logger.info("âœ… Memory optimizations applied")
    
    def _clear_file_cache(self):
        """Clear Linux file cache to free memory"""
        try:
            logger.info("   ğŸ§¹ Clearing Linux file cache...")
            
            # First try to clear just pagecache
            result = os.system("echo 1 | sudo tee /proc/sys/vm/drop_caches > /dev/null 2>&1")
            if result == 0:
                logger.info("      âœ… Page cache cleared")
            else:
                logger.warning("      âš ï¸ Could not clear cache (need sudo)")
                
        except Exception as e:
            logger.warning(f"   âš ï¸ Cache clearing failed: {e}")
    
    def _force_garbage_collection(self):
        """Force Python garbage collection"""
        logger.info("   ğŸ—‘ï¸ Forcing garbage collection...")
        
        # Force garbage collection multiple times
        for i in range(3):
            collected = gc.collect()
            logger.info(f"      GC pass {i+1}: {collected} objects collected")
        
        # Clear any lingering references
        gc.disable()
        gc.enable()
        
        logger.info("      âœ… Garbage collection complete")
    
    def _optimize_buffer_allocation(self):
        """Suggest buffer allocation optimizations"""
        logger.info("   ğŸ“Š Buffer Allocation Strategy:")
        logger.info("      ğŸ’¡ Prioritize VRAM over GTT for frequently accessed weights")
        logger.info("      ğŸ’¡ Use GTT only for overflow when VRAM is full")
        logger.info("      ğŸ’¡ Implement buffer pooling to reduce fragmentation")
        logger.info("      ğŸ’¡ Release memory-mapped files immediately after loading")


class OptimizedMemoryPipeline:
    """Pipeline with optimized memory allocation strategy"""
    
    def __init__(self):
        self.memory_analyzer = MemoryAnalyzer()
        self.vram_budget_gb = 14.0  # Conservative VRAM budget
        self.gtt_budget_gb = 12.0   # Conservative GTT budget
        self.allocated_vram = 0.0
        self.allocated_gtt = 0.0
        
        logger.info("ğŸš€ Optimized Memory Pipeline initialized")
    
    def analyze_current_allocation(self):
        """Analyze current memory allocation patterns"""
        logger.info("\nğŸ“Š Current Memory Allocation Analysis")
        
        # Get initial state
        initial_mem = self.memory_analyzer.print_memory_analysis("INITIAL STATE")
        
        # Analyze issues
        self.memory_analyzer.analyze_memory_allocation_issues()
        
        return initial_mem
    
    def propose_optimal_allocation_strategy(self):
        """Propose optimal memory allocation strategy for 26GB model"""
        logger.info("\nğŸ’¡ Optimal Allocation Strategy for 26GB Model:")
        logger.info("=" * 60)
        
        # Strategy breakdown
        strategies = [
            {
                'name': 'VRAM Priority Strategy',
                'vram_gb': 14.0,
                'gtt_gb': 12.0,
                'description': 'Prioritize most-used layers in VRAM'
            },
            {
                'name': 'Balanced Strategy', 
                'vram_gb': 13.0,
                'gtt_gb': 13.0,
                'description': 'Equal distribution with overhead buffer'
            },
            {
                'name': 'GTT Minimized Strategy',
                'vram_gb': 15.0,
                'gtt_gb': 11.0,
                'description': 'Maximize VRAM usage, minimize GTT'
            }
        ]
        
        for i, strategy in enumerate(strategies, 1):
            logger.info(f"\n{i}. {strategy['name']}:")
            logger.info(f"   ğŸ“ VRAM: {strategy['vram_gb']:.1f} GB")
            logger.info(f"   ğŸ“ GTT:  {strategy['gtt_gb']:.1f} GB")
            logger.info(f"   ğŸ“ Total: {strategy['vram_gb'] + strategy['gtt_gb']:.1f} GB")
            logger.info(f"   ğŸ“ {strategy['description']}")
        
        # Memory layout optimization
        logger.info(f"\nğŸ¯ Recommended Layout:")
        logger.info(f"   ğŸ”¥ Hot layers (0-20):     VRAM (frequent access)")
        logger.info(f"   ğŸŒ¡ï¸  Warm layers (21-40):   VRAM (medium access)")
        logger.info(f"   â„ï¸  Cold layers (41-61):   GTT (infrequent access)")
        logger.info(f"   ğŸ“¦ Embeddings:            VRAM (shared across layers)")
        logger.info(f"   ğŸ“Š Overhead buffer:       2GB VRAM + 1GB GTT")
        
        return strategies[0]  # Return VRAM priority strategy
    
    def implement_memory_optimizations(self):
        """Implement memory optimizations"""
        logger.info("\nğŸ› ï¸ Implementing Memory Optimizations...")
        
        # Apply optimizations
        self.memory_analyzer.optimize_memory_allocation()
        
        # Get optimized state
        optimized_mem = self.memory_analyzer.print_memory_analysis("AFTER OPTIMIZATION")
        
        return optimized_mem
    
    def create_optimized_loader_strategy(self):
        """Create optimized model loading strategy"""
        logger.info("\nğŸ“‹ Optimized Loading Strategy:")
        
        loading_plan = {
            'phase_1_vram': {
                'description': 'Load critical components to VRAM first',
                'components': [
                    'Embeddings (1.3GB)',
                    'Layers 0-15 attention weights (6.4GB)', 
                    'Layers 0-15 FFN weights (6.4GB)',
                    'Output projection (0.3GB)'
                ],
                'total_gb': 14.4
            },
            'phase_2_gtt': {
                'description': 'Load remaining components to GTT',
                'components': [
                    'Layers 16-30 weights (6.0GB)',
                    'Layers 31-45 weights (6.0GB)', 
                    'Layers 46-61 weights (6.4GB)'
                ],
                'total_gb': 12.4
            },
            'phase_3_cleanup': {
                'description': 'Release temporary allocations',
                'actions': [
                    'Close memory-mapped files',
                    'Release intermediate buffers',
                    'Clear file cache',
                    'Force garbage collection'
                ]
            }
        }
        
        for phase, details in loading_plan.items():
            logger.info(f"\nğŸ”„ {phase.upper()}:")
            logger.info(f"   ğŸ“ {details['description']}")
            
            if 'components' in details:
                for component in details['components']:
                    logger.info(f"      âœ… {component}")
                logger.info(f"   ğŸ“Š Total: {details['total_gb']:.1f} GB")
            elif 'actions' in details:
                for action in details['actions']:
                    logger.info(f"      ğŸ§¹ {action}")
        
        total_model_size = loading_plan['phase_1_vram']['total_gb'] + loading_plan['phase_2_gtt']['total_gb']
        logger.info(f"\nğŸ“ˆ Total Model Size: {total_model_size:.1f} GB")
        logger.info(f"   ğŸ¯ Target: 26GB model efficiently loaded")
        
        return loading_plan


def analyze_and_optimize_memory():
    """Complete memory analysis and optimization"""
    import logging
    logging.basicConfig(level=logging.INFO)
    
    logger.info("ğŸ” Starting Comprehensive Memory Analysis")
    
    # Initialize analyzer
    pipeline = OptimizedMemoryPipeline()
    
    # Step 1: Analyze current state
    logger.info("\n" + "="*60)
    logger.info("STEP 1: CURRENT STATE ANALYSIS")
    logger.info("="*60)
    initial_mem = pipeline.analyze_current_allocation()
    
    # Step 2: Propose optimal strategy
    logger.info("\n" + "="*60)
    logger.info("STEP 2: OPTIMAL ALLOCATION STRATEGY")
    logger.info("="*60)
    optimal_strategy = pipeline.propose_optimal_allocation_strategy()
    
    # Step 3: Create loading plan
    logger.info("\n" + "="*60)
    logger.info("STEP 3: OPTIMIZED LOADING PLAN")
    logger.info("="*60)
    loading_plan = pipeline.create_optimized_loader_strategy()
    
    # Step 4: Apply optimizations
    logger.info("\n" + "="*60)
    logger.info("STEP 4: APPLY OPTIMIZATIONS")
    logger.info("="*60)
    optimized_mem = pipeline.implement_memory_optimizations()
    
    # Step 5: Summary and recommendations
    logger.info("\n" + "="*60)
    logger.info("STEP 5: SUMMARY AND RECOMMENDATIONS")
    logger.info("="*60)
    
    logger.info("\nğŸ¯ Key Issues Identified:")
    logger.info("   1. ğŸš¨ Over-allocation: GTT using ~40GB instead of ~12GB")
    logger.info("   2. ğŸš¨ Under-utilization: VRAM only using ~12GB instead of ~15GB")
    logger.info("   3. ğŸš¨ File cache bloat: 40GB+ cache not releasing after loading")
    logger.info("   4. ğŸš¨ Memory fragmentation: Inefficient buffer allocation")
    
    logger.info("\nğŸ’¡ Recommended Solutions:")
    logger.info("   1. âœ… Implement VRAM-priority allocation strategy")
    logger.info("   2. âœ… Close memory-mapped files immediately after loading")
    logger.info("   3. âœ… Clear file cache after model loading")
    logger.info("   4. âœ… Use buffer pooling to reduce fragmentation")
    logger.info("   5. âœ… Monitor allocation patterns during loading")
    
    logger.info("\nğŸš€ Expected Results:")
    logger.info("   ğŸ“‰ RAM usage: 96GB â†’ 60GB (release 36GB file cache)")
    logger.info("   ğŸ“ˆ VRAM usage: 12GB â†’ 15GB (better utilization)")
    logger.info("   ğŸ“‰ GTT usage: 40GB â†’ 12GB (eliminate over-allocation)")
    logger.info("   ğŸ¯ Total efficiency: 26GB model using 27GB total (optimal)")
    
    return {
        'initial_memory': initial_mem,
        'optimal_strategy': optimal_strategy,
        'loading_plan': loading_plan,
        'optimized_memory': optimized_mem
    }


if __name__ == "__main__":
    analyze_and_optimize_memory()