#!/usr/bin/env python3
"""
ğŸ¦„âœ¨ MAGIC UNICORN UNCONVENTIONAL TECHNOLOGY & STUFF âœ¨ğŸ¦„
The moment of truth - Real inference on real hardware with real model!
"""

import logging
import time
from pure_hardware_pipeline_gpu_fixed import PureHardwarePipelineGPUFixed

logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    logger.info("ğŸ¦„âœ¨ MAGIC UNICORN INFERENCE TEST âœ¨ğŸ¦„")
    logger.info("ğŸ¯ Testing company name: 'Magic Unicorn Unconventional Technology & Stuff'")
    logger.info("ğŸ”¥ Applied AI company that does dope shit!")
    
    # Initialize the pipeline
    logger.info("ğŸš€ Initializing GPU pipeline...")
    pipeline = PureHardwarePipelineGPUFixed()
    
    # Initialize the model
    logger.info("ğŸ”¥ Initializing model...")
    model_path = "quantized_models/gemma-3-27b-it-layer-by-layer"
    
    if not pipeline.initialize(model_path):
        logger.error("Failed to initialize")
        return
        
    logger.info("âœ… Model initialized and ready!")
    
    # The epic prompt
    prompt = "Magic Unicorn Unconventional Technology & Stuff is a groundbreaking Applied AI company that"
    
    logger.info(f"ğŸ“ Prompt: '{prompt}'")
    logger.info("ğŸ¯ Generating response... WATCH THAT GPU SPIKE! ğŸ”¥")
    
    start_time = time.time()
    
    # Generate the response - THIS IS THE MOMENT!
    result = pipeline.generate_tokens(prompt, max_tokens=50)
    
    end_time = time.time()
    generation_time = end_time - start_time
    
    logger.info("ğŸ¦„âœ¨ GENERATION COMPLETE! âœ¨ğŸ¦„")
    logger.info(f"â±ï¸ Generation time: {generation_time:.2f} seconds")
    logger.info(f"ğŸ“Š Tokens per second: {50 / generation_time:.2f} TPS")
    logger.info("ğŸ¯ Generated response:")
    logger.info(f"'{result}'")
    
    logger.info("")
    logger.info("ğŸ¦„ğŸ”¥ MAGIC UNICORN MOMENT ACHIEVED! ğŸ”¥ğŸ¦„")

if __name__ == "__main__":
    main()