{
  "model_info": {
    "name": "4B",
    "total_layers": 32,
    "hidden_size": 4096
  },
  "hardware_mapping": {
    "npu_phoenix": {
      "target": "Attention layers",
      "layers": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15
      ],
      "operations": [
        "Q projection",
        "K projection",
        "V projection",
        "Attention",
        "O projection"
      ],
      "quantization": "INT4 weights, INT8 activations",
      "memory_mb": 768
    },
    "vulkan_igpu": {
      "target": "FFN layers",
      "layers": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31
      ],
      "operations": [
        "Gate projection",
        "Up projection",
        "SiLU activation",
        "Down projection"
      ],
      "quantization": "INT4 weights, INT8 activations",
      "memory_mb": 1024
    },
    "cpu_orchestrator": {
      "target": "Control and data movement",
      "operations": [
        "Tokenization",
        "Layer orchestration",
        "Memory management"
      ],
      "memory_mb": 1024
    }
  },
  "performance_targets": {
    "npu_tps": 50,
    "vulkan_tps": 100,
    "combined_tps": 150,
    "latency_ms": 20
  },
  "optimization_strategy": {
    "pipeline_depth": 4,
    "prefetch_layers": 2,
    "async_execution": true,
    "memory_streaming": true
  }
}